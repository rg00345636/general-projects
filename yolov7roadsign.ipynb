{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1181356,"sourceType":"datasetVersion","datasetId":671172},{"sourceId":2332556,"sourceType":"datasetVersion","datasetId":1407957}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -r requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom IPython.display import Image  # for displaying images\nimport os \nimport random\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport xml.etree.ElementTree as ET\nfrom xml.dom import minidom\nfrom tqdm import tqdm\nfrom PIL import Image, ImageDraw\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nrandom.seed(108)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%mkdir Road_Sign_Dataset\n%cd Road_Sign_Dataset\n!mkdir annotations\n!mkdir images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/Road_Sign_Dataset\n!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!rm -R Road_Sign_Dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -R /kaggle/input/tbx-11/TBX11K/annotations/xml/* /kaggle/working/Road_Sign_Dataset/annotations\n!cp -R /kaggle/input/tbx-11/TBX11K/imgs/tb/* /kaggle/working/Road_Sign_Dataset/images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd\n!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you're in the data folder\n!cat /kaggle/working/Road_Sign_Dataset/annotations/tb0004.xml","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = ET.parse('/kaggle/working/Road_Sign_Dataset/annotations/tb0026.xml').getroot()\nroot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get the data from XML Annotation\ndef extract_info_from_xml(xml_file):\n    root = ET.parse(xml_file).getroot()\n    \n    # Initialise the info dict \n    info_dict = {}\n    info_dict['bboxes'] = []\n\n    # Parse the XML Tree\n    for elem in root:\n        # Get the file name \n        if elem.tag == \"filename\":\n            info_dict['filename'] = elem.text + '.xml'\n            \n        # Get the image size\n        elif elem.tag == \"size\":\n            image_size = []\n            for subelem in elem:\n                image_size.append(int(subelem.text))\n            \n            info_dict['image_size'] = tuple(image_size)\n        \n        # Get details of the bounding box \n        elif elem.tag == \"object\":\n            bbox = {}\n            for subelem in elem:\n                if subelem.tag == \"name\":\n                    bbox[\"class\"] = subelem.text\n                    \n                elif subelem.tag == \"bndbox\":\n                    for subsubelem in subelem:\n                        bbox[subsubelem.tag] = int(subsubelem.text)            \n            info_dict['bboxes'].append(bbox)\n    \n    return info_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.remove('/kaggle/working/Road_Sign_Dataset/annotations/tb1199.xml')\nos.remove('/kaggle/working/Road_Sign_Dataset/images/tb1199.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(extract_info_from_xml('/kaggle/working/Road_Sign_Dataset/annotations/tb0004.xml'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{'bboxes': [{'class': 'trafficlight', 'xmin': 20, 'ymin': 109, 'xmax': 81, 'ymax': 237}, {'class': 'trafficlight', 'xmin': 116, 'ymin': 162, 'xmax': 163, 'ymax': 272}, {'class': 'trafficlight', 'xmin': 189, 'ymin': 189, 'xmax': 233, 'ymax': 295}], 'filename': 'road4.png', 'image_size': (267, 400, 3)}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dictionary that maps class names to IDs\nclass_name_to_id_mapping = {\"ActiveTuberculosis\": 0,\n                           \"ObsoletePulmonaryTuberculosis\": 1}\n                            #,\n                           #\"speedlimit\": 2,\n                           #\"crosswalk\": 3}\n\n# Convert the info dict to the required yolo format and write it to disk\ndef convert_to_yolov5(info_dict):\n    print_buffer = []\n    \n    # For each bounding box\n    for b in info_dict[\"bboxes\"]:\n        try:\n            class_id = class_name_to_id_mapping[b[\"class\"]]\n        except KeyError:\n            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n        \n        # Transform the bbox co-ordinates as per the format required by YOLO v5\n        b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2 \n        b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n        b_width    = (b[\"xmax\"] - b[\"xmin\"])\n        b_height   = (b[\"ymax\"] - b[\"ymin\"])\n        \n        # Normalise the co-ordinates by the dimensions of the image\n        image_c = 3\n        image_w, image_h = info_dict[\"image_size\"]  \n        b_center_x /= image_w \n        b_center_y /= image_h \n        b_width    /= image_w \n        b_height   /= image_h \n        \n        #Write the bbox details to the file \n        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n    \n    #print(info_dict[\"filename\"])\n    # Name of the file which we have to save \n    save_file_name = os.path.join(\"annotations\", info_dict[\"filename\"].replace(\".xml\", \".txt\"))\n    \n    # Save the annotation to disk\n    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"xml\"]\n#annotations.sort()\n#annotations","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the annotations\nannotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"xml\"]\nannotations.sort()\n\n# Convert and save the annotations\nfor ann in tqdm(annotations):\n    info_dict = extract_info_from_xml(ann)\n    #print(info_dict)\n    convert_to_yolov5(info_dict)\nannotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#{'bboxes': [{'class': 'ObsoletePulmonaryTuberculosis', 'xmin': 1446, 'ymin': 250, 'xmax': 2007, 'ymax': 1017}, {'class': 'ObsoletePulmonaryTuberculosis', 'xmin': 618, 'ymin': 391, 'xmax': 1177, 'ymax': 1013}], 'filename': 'tb0003', 'image_size': (2840, 2827)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing the annotations","metadata":{}},{"cell_type":"code","source":"#annotations","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annotation_file = random.choice(annotations)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(0)\n\nclass_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n\ndef plot_bounding_box(image, annotation_list):\n    annotations = np.array(annotation_list)\n    w, h = image.size\n    \n    plotted_image = ImageDraw.Draw(image)\n\n    transformed_annotations = np.copy(annotations)\n    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n    \n    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n    \n    for ann in transformed_annotations:\n        obj_cls, x0, y0, x1, y1 = ann\n        plotted_image.rectangle(((x0,y0), (x1,y1)))\n        \n        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n    \n    plt.imshow(np.array(image))\n    plt.show()\n\n# Get any random annotation file \nannotation_file = random.choice(annotations)\nwith open(annotation_file, \"r\") as file:\n    annotation_list = file.read().split(\"\\n\")[:-1]\n    annotation_list = [x.split(\" \") for x in annotation_list]\n    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n\n#Get the corresponding image file\nimage_file = annotation_file.replace(\"annotations\", \"images\").replace(\"txt\", \"png\")\nassert os.path.exists(image_file)\n\n#Load the image\nimage = Image.open(image_file)\n\n#Plot the Bounding Box\nplot_bounding_box(image, annotation_list)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Partition the dataset","metadata":{}},{"cell_type":"code","source":"annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]\n#annotations","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read images and annotations\nimages = [os.path.join('images', x) for x in os.listdir('images')]\nannotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]\n\nimages.sort()\nannotations.sort()\n\n# Split the dataset into train-valid-test splits \ntrain_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\nval_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir images/train \n!mkdir images/val \n!mkdir images/test \n\n!mkdir annotations/train \n!mkdir annotations/val \n!mkdir annotations/test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir('/kaggle/working/Road_Sign_Dataset/images/train'))\n#len(os.listdir('/kaggle/working/Road_Sign_Dataset/images/test'))\n#len(os.listdir('/kaggle/working/Road_Sign_Dataset/images/val'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Utility function to move images \ndef move_files_to_folder(list_of_files, destination_folder):\n    for f in list_of_files:\n        try:\n            shutil.move(f, destination_folder)\n        except:\n            print(f)\n            assert False\n\n# Move the splits into their folders\nmove_files_to_folder(train_images, '/kaggle/working/Road_Sign_Dataset/images/train')\nmove_files_to_folder(val_images, '/kaggle/working/Road_Sign_Dataset/images/val/')\nmove_files_to_folder(test_images, '/kaggle/working/Road_Sign_Dataset/images/test/')\nmove_files_to_folder(train_annotations, '/kaggle/working/Road_Sign_Dataset/annotations/train/')\nmove_files_to_folder(val_annotations, '/kaggle/working/Road_Sign_Dataset/annotations/val/')\nmove_files_to_folder(test_annotations, '/kaggle/working/Road_Sign_Dataset/annotations/test/')\n!mv annotations labels\n%cd ../","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/Road_Sign_Dataset/\n!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir('/kaggle/working/Road_Sign_Dataset/labels/train/'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget -P data/ https://gist.githubusercontent.com/ayooshkathuria/bcf7e3c929cbad445439c506dba6198d/raw/f437350c0c17c4eaa1e8657a5cb836e65d8aa08a/road_sign_data.yaml\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# INSTALL","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/WongKinYiu/yolov7.git &> /dev/null","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd yolov7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r requirements.txt &> /dev/null","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6e.pt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/tkeldenich/How_to_use_YOLOv7_Tutorial/main/man_cafe.jpg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nim = Image.open('man_cafe.jpg')\nim","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py --weights yolov7-e6e.pt --source ./man_cafe.jpg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_res1 = Image.open('./runs/detect/exp/man_cafe.jpg')\nim_res1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py --weights yolov7-e6e.pt --conf 0.60 --img-size 640 --source ./man_cafe.jpg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_res2 = Image.open('./runs/detect/exp2/man_cafe.jpg')\nim_res2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py --weights yolov7-tiny.pt --conf 0.25 --img-size 640 --source ./man_cafe.jpg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_res3 = Image.open('./runs/detect/exp3/man_cafe.jpg')\nim_res3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -R /kaggle/working/Road_Sign_Dataset/data/road_sign_data.yaml /kaggle/working/Road_Sign_Dataset/yolov7/data/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yamltext = \"\"\"\ntrain: /kaggle/working/Road_Sign_Dataset/images/train/ \nval:  /kaggle/working/Road_Sign_Dataset/images/val/\ntest: /kaggle/working/Road_Sign_Dataset/images/test/\n\n# number of classes\nnc: 2\n\n# class names\nnames: [\"ActiveTuberculosis\",\"ObsoletePulmonaryTuberculosis\"]\n\n\"\"\"\n\nwith open(\"/kaggle/working/Road_Sign_Dataset/yolov7/data/road_sign_data.yaml\", 'w') as file:\n    file.write(yamltext)\n\n#%cat /kaggle/working/data/data.yaml\n\n\n!cat /kaggle/working/Road_Sign_Dataset/yolov7/data/road_sign_data.yaml","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd Road_Sign_Dataset/yolov7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir('/kaggle/working/Road_Sign_Dataset/images/train/'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train for 60 Epochs","metadata":{}},{"cell_type":"code","source":"!python train.py --img-size 512 --cfg cfg/training/yolov7.yaml --hyp data/hyp.scratch.custom.yaml --batch 8 --epochs 10 --data data/road_sign_data.yaml --weights yolov7-e6e.pt --workers 24 --name yolo_road_det","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train for 120 Epochs","metadata":{}},{"cell_type":"code","source":"!python train.py --img-size 512 --cfg cfg/training/yolov7.yaml --hyp data/hyp.scratch.custom.yaml --batch 8 --epochs 130 --data data/road_sign_data.yaml --weights yolov7-e6e.pt --workers 24 --name yolo_det31Aug_130","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference for Train Run of 60 Epochs","metadata":{}},{"cell_type":"code","source":"!python detect.py --source /kaggle/working/Road_Sign_Dataset/images/test/ --weights runs/train/yolo_road_det5/weights/best.pt --conf 0.05 --name yolo_road_det5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detections_dir = \"runs/detect/yolo_road_det5/\"\ndetection_images = [os.path.join(detections_dir, x) for x in os.listdir(detections_dir)]\n\nrandom_detection_image = Image.open(random.choice(detection_images))\nplt.imshow(np.array(random_detection_image))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# No weights","metadata":{}},{"cell_type":"code","source":"!python train.py --img-size 512 --cfg cfg/training/yolov7.yaml --hyp data/hyp.scratch.custom.yaml --batch 8 --epochs 10 --data data/road_sign_data.yaml --weights '' --workers 24 --name yolo_det31Aug_noweights\n\n\n#yolov7-e6e.pt ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python test.py --weights runs/train/yolo_road_det3/weights/best.pt --data road_sign_data.yaml --task test --name yolo_det","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference for 130 Epochs","metadata":{}},{"cell_type":"code","source":"!python detect.py --source /kaggle/working/Road_Sign_Dataset/images/test/ --weights runs/train/yolo_det31Aug_130/weights/best.pt --conf 0.05 --name yolo_road_det5\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detections_dir = \"runs/detect/yolo_road_det52/\"\ndetection_images = [os.path.join(detections_dir, x) for x in os.listdir(detections_dir)]\n\nrandom_detection_image = Image.open(random.choice(detection_images))\nplt.imshow(np.array(random_detection_image))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}